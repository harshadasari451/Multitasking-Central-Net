{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HzYQpf4i1q_r"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Installing modules"
      ],
      "metadata": {
        "id": "UNqV9961hHn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "DAUYlcV09-yE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6daf992c-01b1-4f2c-fccd-431df510b0de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mounting *drive*"
      ],
      "metadata": {
        "id": "QDvXloZMLL7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HEj8fMDLTNN",
        "outputId": "f9572fb3-7280-4907-bdbb-321f8e3f7739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "PfaWzpaBLios"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing libraries and modules"
      ],
      "metadata": {
        "id": "N02IpR5M5f6f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axseu8IQxHd8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import RobertaModel, RobertaTokenizer\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "\n",
        "import re\n",
        "import json\n",
        "import random\n",
        "import shutil\n",
        "import argparse\n",
        "import functools\n",
        "import contextlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "import time\n",
        "import logging\n",
        "from datetime import timedelta\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing data"
      ],
      "metadata": {
        "id": "ff61ZYXxcZP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel(\"/content/drive/MyDrive/MM_AMZN_RW_DATA/Domain_wise_datasets/fashion_data_webent.xlsx\")\n",
        "dataset.drop(columns = ['Complaint Overall', 'Emotion Overall', 'Sentiment Overall','Emotion.0', 'Emotion.1', 'Emotion.2', 'Emotion.3', 'Comments'], inplace = True)\n",
        "dataset = dataset.iloc[0:1096,:]\n",
        "dataset.columns"
      ],
      "metadata": {
        "id": "v6Id5Eq9AXi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e68a226-5015-4900-abb6-5e7b3e269e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Title', 'Review_S', 'Aspect_Term1', 'Comp_Analysis1', 'Aspect_Term2',\n",
              "       'Comp_Analysis2', 'Aspect_Term3', 'Comp_Analysis3', 'Aspect_Term4',\n",
              "       'Comp_Analysis4', 'Image_urls', 'Web_entities'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definining hyperparameters"
      ],
      "metadata": {
        "id": "0g16ElQ75jki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sz = 8\n",
        "drop_img_percent=0.0\n",
        "dropout=0.1\n",
        "embed_sz=300\n",
        "freeze_img=0\n",
        "freeze_txt=0\n",
        "gradient_accumulation_steps=24\n",
        "hidden=[]\n",
        "hidden_sz=768\n",
        "img_embed_pool_type=\"avg\"\n",
        "img_hidden_sz=2048\n",
        "include_bn=True\n",
        "lr=1e-4\n",
        "lr_factor=0.5\n",
        "lr_patience=2\n",
        "max_epochs=50\n",
        "max_seq_len=512\n",
        "model_name=\"mmbt\"\n",
        "n_workers=2\n",
        "name=\"nameless\"\n",
        "num_image_embeds=1\n",
        "patience=10\n",
        "savedir=\"/content/save_dir/\"\n",
        "seed=42\n",
        "task=\"mmimdb\"\n",
        "task_type= \"multilabel\"#, \"classification\"]\n",
        "warmup=0.1\n",
        "weight_classes=1\n",
        "n_classes = 7\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\", return_dict=True, do_lower_case=True)"
      ],
      "metadata": {
        "id": "Lu2zm-4Z_Jjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "HpAEjwheLeN-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting data in lists"
      ],
      "metadata": {
        "id": "tcQ66AzuJf6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_title_review_comb(X_reviews):\n",
        "    title_review_comb = []\n",
        "    for i in range(X_reviews.shape[0]):\n",
        "        if(str(type(X_reviews.iloc[i,0])) == \"<class 'str'>\"):\n",
        "          title_review_comb.append(X_reviews.iloc[i,0]+X_reviews.iloc[i,1])\n",
        "        else:\n",
        "          # print(i)\n",
        "          title_review_comb.append(X_reviews.iloc[i,1])\n",
        "\n",
        "    text_reviews = []\n",
        "    for i in range(X_reviews.shape[0]):\n",
        "        words = re.split(r'\\W+', title_review_comb[i])\n",
        "\n",
        "        words = [word.lower() for word in words]\n",
        "        text = ' '.join(words)\n",
        "        words = text.split()\n",
        "        text = ' '.join(words)\n",
        "        text_reviews.append(text)\n",
        "\n",
        "    return text_reviews\n",
        "\n",
        "def check_aspect(aspect,j):\n",
        "  aspects = []\n",
        "  for i in [0,1,2,3]:\n",
        "    val = aspect[i][j]\n",
        "    if(str(val) == 'nan'):\n",
        "      continue\n",
        "    elif(val == 'fabric'):\n",
        "      aspects.append('quality')\n",
        "    else:\n",
        "      aspects.append(val)\n",
        "  return aspects\n",
        "\n",
        "\n",
        "def get_labels(df):\n",
        "    aspect = [list(df['Aspect_Term1']), list(df['Aspect_Term2']), list(df['Aspect_Term3']), list(df['Aspect_Term4'])]\n",
        "    aspects = []\n",
        "\n",
        "    for i in range(df.shape[0]):\n",
        "        aspects.append(check_aspect(aspect,i))\n",
        "\n",
        "    return aspects\n",
        "\n",
        "def get_web_entities(dataset):\n",
        "    web_entities = []\n",
        "    for mul_entities in list(dataset['Web_entities']):\n",
        "      lables_list = (re.sub(\"[^a-zA-Z0-9,.)]\", \" \", mul_entities)).split(',')\n",
        "      # print(lables_list)\n",
        "      lables_list_mod = []\n",
        "      for label in lables_list:\n",
        "        label_mod = \" \".join(label.split())\n",
        "        # print(label_mod)\n",
        "        if(label_mod == ''):\n",
        "          continue\n",
        "        lables_list_mod.append(label_mod.lower())\n",
        "\n",
        "      web_entities.append(lables_list_mod)\n",
        "\n",
        "    return web_entities\n",
        "\n",
        "imgs_path = '/content/drive/MyDrive/MM_AMZN_RW_DATA/Domain_wise_images/images_new/'\n",
        "dir = os.listdir(imgs_path)\n",
        "dir.sort()\n",
        "directory = dir[965:1275]\n",
        "directory+=(dir[:965])\n",
        "for i in range(len(directory)):\n",
        "  directory[i] = imgs_path+directory[i]\n",
        "\n",
        "images_path = directory[0:1096]\n",
        "text_review = get_title_review_comb(dataset)\n",
        "web_entities = get_web_entities(dataset)\n",
        "aspect_labels = get_labels(dataset)\n",
        "\n",
        "print(len(aspect_labels))\n",
        "print(len(text_review))\n",
        "print(len(web_entities))\n",
        "print(len(images_path))"
      ],
      "metadata": {
        "id": "9dxomkhbnUd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea2c4502-184c-4a86-dd8e-70e8ac8ab51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1096\n",
            "1096\n",
            "1096\n",
            "1096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting dataset"
      ],
      "metadata": {
        "id": "yXkxYpR-KAjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First Split for Train and Test\n",
        "text_train,text_test, web_ent_train,web_ent_test, img_train,img_test, y1_train,y1_test  = train_test_split(np.array(text_review), np.array(web_entities), np.array(images_path),\n",
        "                                                                                                           np.array(aspect_labels), test_size=0.1, random_state=seed, shuffle=True)\n",
        "# Next split Train in to training and validation\n",
        "text_tr,text_val, web_ent_tr,web_ent_val, img_tr,img_val, y1_tr,y1_val = train_test_split(text_train, web_ent_train, img_train, y1_train, test_size=0.2, random_state = seed, shuffle=True)\n",
        "\n",
        "# print(web_ent_tr.shape)\n",
        "# print(web_ent_test.shape)\n",
        "# print(web_ent_val.shape)"
      ],
      "metadata": {
        "id": "m6ULUkGopxP2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e0ecaf-0565-4c3a-ff7c-238656903b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(788,)\n",
            "(110,)\n",
            "(198,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-ca13545d58ed>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  text_train,text_test, web_ent_train,web_ent_test, img_train,img_test, y1_train,y1_test  = train_test_split(np.array(text_review), np.array(web_entities), np.array(images_path),\n",
            "<ipython-input-26-ca13545d58ed>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  np.array(aspect_labels), test_size=0.1, random_state=seed, shuffle=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Functions and Classes"
      ],
      "metadata": {
        "id": "tzpZesq9cdIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classes and Utility functions\n"
      ],
      "metadata": {
        "id": "boGgABuxF1oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, checkpoint_path, filename=\"checkpoint.pt\"):\n",
        "    filename = os.path.join(checkpoint_path, filename)\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, os.path.join(checkpoint_path, \"model_best.pt\"))\n",
        "\n",
        "\n",
        "def load_checkpoint(model, path):\n",
        "    best_checkpoint = torch.load(path)\n",
        "    model.load_state_dict(best_checkpoint[\"state_dict\"])\n",
        "\n",
        "\n",
        "def truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\n",
        "    Copied from https://github.com/huggingface/pytorch-pretrained-BERT\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()\n",
        "\n",
        "\n",
        "def log_metrics(set_name, metrics, logger):\n",
        "        logger.info(\n",
        "            \"{}: Loss_mean_overall: {:.5f} | Macro F1 {:.5f} | Micro F1: {:.5f}\".format(\n",
        "                set_name, metrics[\"loss_mean_overall\"], metrics[\"macro_f1\"], metrics[\"micro_f1\"]\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def numpy_seed(seed, *addl_seeds):\n",
        "    \"\"\"Context manager which seeds the NumPy PRNG with the specified seed and\n",
        "    restores the state afterward\"\"\"\n",
        "    if seed is None:\n",
        "        yield\n",
        "        return\n",
        "    if len(addl_seeds) > 0:\n",
        "        seed = int(hash((seed, *addl_seeds)) % 1e6)\n",
        "    state = np.random.get_state()\n",
        "    np.random.seed(seed)\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        np.random.set_state(state)\n",
        "\n",
        "def get_labels_and_frequencies(aspects):\n",
        "    label_freqs = Counter()\n",
        "    data_labels = aspects\n",
        "    if type(data_labels[0]) == list:\n",
        "        for label_row in data_labels:\n",
        "            label_freqs.update(label_row)\n",
        "    else:\n",
        "        label_freqs.update(data_labels)\n",
        "\n",
        "    return list(label_freqs.keys()), label_freqs\n",
        "\n",
        "aspect_label, aspect_label_freqs = get_labels_and_frequencies(aspect_labels)\n",
        "print(aspect_label_freqs)"
      ],
      "metadata": {
        "id": "-sIYRjwK5nWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1723339c-5c41-4d23-86dd-79e28a1892af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'quality': 704, 'fit': 390, 'service': 296, 'price': 282, 'style': 240, 'color': 231, 'misc': 65})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class JsonlDataset(Dataset):\n",
        "    def __init__(self, reviews, web_entities, images_path, labels, tokenizer, transforms):\n",
        "        self.text_data = reviews\n",
        "        self.web_entities = web_entities\n",
        "        self.img_data = images_path\n",
        "        self.aspect_data = labels\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        self.text_start_token = [\"<s>\"] if model_name != \"mmbt\" else [\"</s>\"]\n",
        "\n",
        "        self.max_seq_len = max_seq_len - num_image_embeds\n",
        "\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sent1 = self.tokenizer.tokenize(self.text_data[index])\n",
        "        sent2 = self.tokenizer.tokenize(\" \".join(self.web_entities[index]))\n",
        "        truncate_seq_pair(sent1, sent2, self.max_seq_len - 3)\n",
        "\n",
        "        sentence = self.text_start_token + sent1 + [\"</s>\"] + sent2 + [\"</s>\"]\n",
        "        segment = torch.cat(\n",
        "                [torch.zeros(2 + len(sent1)), torch.ones(len(sent2) + 1)]\n",
        "            )\n",
        "\n",
        "        sentence = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(sentence))\n",
        "\n",
        "        label = torch.zeros(7)\n",
        "        label[\n",
        "              [aspect_label.index(tgt) for tgt in self.aspect_data[index]]\n",
        "            ] = 1\n",
        "\n",
        "        image = None\n",
        "        if self.img_data[index]:\n",
        "            image = Image.open(self.img_data[index]).convert(\"RGB\")\n",
        "        else:\n",
        "            image = Image.fromarray(128 * np.ones((256, 256, 3), dtype=np.uint8))\n",
        "        image = self.transforms(image)\n",
        "\n",
        "        # The first SEP is part of Image Token.\n",
        "        segment = segment[1:]\n",
        "        sentence = sentence[1:]\n",
        "        # The first segment (0) is of images.\n",
        "        segment += 1\n",
        "\n",
        "        return sentence, segment, image, label\n",
        "\n",
        "\n",
        "\n",
        "class LogFormatter:\n",
        "    def __init__(self):\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def format(self, record):\n",
        "        elapsed_seconds = round(record.created - self.start_time)\n",
        "\n",
        "        prefix = \"%s - %s - %s\" % (\n",
        "            record.levelname,\n",
        "            time.strftime(\"%x %X\"),\n",
        "            timedelta(seconds=elapsed_seconds),\n",
        "        )\n",
        "        message = record.getMessage()\n",
        "        message = message.replace(\"\\n\", \"\\n\" + \" \" * (len(prefix) + 3))\n",
        "        return \"%s - %s\" % (prefix, message)\n",
        "\n",
        "\n",
        "def get_transforms():\n",
        "    return transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
        "                std=[0.12221994, 0.12145835, 0.14380469],\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    lens = [len(row[0]) for row in batch]\n",
        "    bsz, max_seq_len = len(batch), max(lens)\n",
        "\n",
        "    mask_tensor = torch.zeros(bsz, max_seq_len).long()\n",
        "    text_tensor = torch.zeros(bsz, max_seq_len).long()\n",
        "    segment_tensor = torch.zeros(bsz, max_seq_len).long()\n",
        "\n",
        "    img_tensor = None\n",
        "    if model_name in [\"img\", \"concatbow\", \"concatbert\", \"mmbt\"]:\n",
        "        img_tensor = torch.stack([row[2] for row in batch])\n",
        "\n",
        "    # Multilabel case\n",
        "    tgt1_tensor = torch.stack([row[3] for row in batch])\n",
        "\n",
        "    for i_batch, (input_row, length) in enumerate(zip(batch, lens)):\n",
        "        tokens, segment = input_row[:2]\n",
        "        text_tensor[i_batch, :length] = tokens\n",
        "        segment_tensor[i_batch, :length] = segment\n",
        "        mask_tensor[i_batch, :length] = 1\n",
        "\n",
        "    return text_tensor, segment_tensor, mask_tensor, img_tensor, tgt1_tensor\n",
        "\n",
        "\n",
        "def get_data_loaders():\n",
        "\n",
        "    transforms = get_transforms()\n",
        "\n",
        "    train = JsonlDataset(text_tr, web_ent_tr, img_tr, y1_tr, tokenizer, transforms)\n",
        "\n",
        "    train_data_len = len(train)\n",
        "\n",
        "    dev = JsonlDataset(text_val,web_ent_val,img_val, y1_val, tokenizer, transforms)\n",
        "\n",
        "    collate = functools.partial(collate_fn)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train,\n",
        "        batch_size=batch_sz,\n",
        "        shuffle=True,\n",
        "        num_workers=n_workers,\n",
        "        collate_fn=collate,\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        dev,\n",
        "        batch_size=batch_sz,\n",
        "        shuffle=False,\n",
        "        num_workers=n_workers,\n",
        "        collate_fn=collate,\n",
        "    )\n",
        "\n",
        "    test_set = JsonlDataset(text_test,web_ent_test,img_test,y1_test, tokenizer, transforms)\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_set,\n",
        "        batch_size=batch_sz,\n",
        "        shuffle=False,\n",
        "        num_workers=n_workers,\n",
        "        collate_fn=collate,\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def create_logger(filepath):\n",
        "    # create log formatter\n",
        "    log_formatter = LogFormatter()\n",
        "\n",
        "    # create file handler and set level to debug\n",
        "    file_handler = logging.FileHandler(filepath, \"a\")\n",
        "    file_handler.setLevel(logging.DEBUG)\n",
        "    file_handler.setFormatter(log_formatter)\n",
        "\n",
        "    # create console handler and set level to info\n",
        "    console_handler = logging.StreamHandler()\n",
        "    console_handler.setLevel(logging.INFO)\n",
        "    console_handler.setFormatter(log_formatter)\n",
        "\n",
        "    # create logger and set level to debug\n",
        "    logger = logging.getLogger()\n",
        "    logger.handlers = []\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "    logger.propagate = False\n",
        "    logger.addHandler(file_handler)\n",
        "    logger.addHandler(console_handler)\n",
        "\n",
        "    # reset logger elapsed time\n",
        "    def reset_time():\n",
        "        log_formatter.start_time = time.time()\n",
        "\n",
        "    logger.reset_time = reset_time\n",
        "\n",
        "    logger.info(\n",
        "        \"\\n\".join(\n",
        "            \"%s: %s\" % (k, str(v))\n",
        "            for k, v in sorted(dict(vars()).items(), key=lambda x: x[0])\n",
        "        )\n",
        "    )\n",
        "    return logger\n",
        "\n",
        "\n",
        "def get_criterion():\n",
        "      if weight_classes:\n",
        "            freqs = [aspect_label_freqs[l] for l in aspect_label]\n",
        "            label_weights = (torch.FloatTensor(freqs) / len(text_tr)) ** -1\n",
        "            criterion = nn.BCEWithLogitsLoss(pos_weight=label_weights.cuda())\n",
        "      else:\n",
        "          criterion = nn.BCEWithLogitsLoss()\n",
        "      return criterion\n",
        "\n",
        "\n",
        "\n",
        "def get_scheduler(optimizer):\n",
        "    return optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, \"max\", patience=lr_patience, verbose=True, factor=lr_factor\n",
        "    )"
      ],
      "metadata": {
        "id": "2ItnOqb-7yIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Modeling"
      ],
      "metadata": {
        "id": "kzDgNKkefhYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RobertaEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RobertaEncoder, self).__init__()\n",
        "        # self.args = args\n",
        "        self.bert = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "    def forward(self, txt, mask, segment):\n",
        "        _, out = self.bert(\n",
        "            txt,\n",
        "            token_type_ids=segment,\n",
        "            attention_mask=mask,\n",
        "            output_all_encoded_layers=False,\n",
        "        )\n",
        "        return out\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        # self.args = args\n",
        "        model = torchvision.models.resnet152(pretrained=True)\n",
        "        modules = list(model.children())[:-2]\n",
        "        self.model = nn.Sequential(*modules)\n",
        "\n",
        "        pool_func = (\n",
        "            nn.AdaptiveAvgPool2d\n",
        "            if img_embed_pool_type == \"avg\"\n",
        "            else nn.AdaptiveMaxPool2d\n",
        "        )\n",
        "\n",
        "        if num_image_embeds in [1, 2, 3, 5, 7]:\n",
        "            self.pool = pool_func((num_image_embeds, 1))\n",
        "        elif num_image_embeds == 4:\n",
        "            self.pool = pool_func((2, 2))\n",
        "        elif num_image_embeds == 6:\n",
        "            self.pool = pool_func((3, 2))\n",
        "        elif num_image_embeds == 8:\n",
        "            self.pool = pool_func((4, 2))\n",
        "        elif num_image_embeds == 9:\n",
        "            self.pool = pool_func((3, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Bx3x224x224 -> Bx2048x7x7 -> Bx2048xN -> BxNx2048\n",
        "        out = self.pool(self.model(x))\n",
        "        out = torch.flatten(out, start_dim=2)\n",
        "        out = out.transpose(1, 2).contiguous()\n",
        "        return out  # BxNx2048\n",
        "\n",
        "class ImageBertEmbeddings(nn.Module):\n",
        "    def __init__(self, embeddings):\n",
        "        super(ImageBertEmbeddings, self).__init__()\n",
        "        # self. =\n",
        "        self.img_embeddings = nn.Linear(img_hidden_sz, hidden_sz)\n",
        "        self.position_embeddings = embeddings.position_embeddings\n",
        "        self.token_type_embeddings = embeddings.token_type_embeddings\n",
        "        self.word_embeddings = embeddings.word_embeddings\n",
        "        self.LayerNorm = embeddings.LayerNorm\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.num_image_embeds = num_image_embeds\n",
        "        # self.vocab = vocab\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def forward(self, input_imgs, token_type_ids):\n",
        "        bsz = input_imgs.size(0)\n",
        "        seq_length = self.num_image_embeds + 2  # +2 for CLS and SEP Token\n",
        "\n",
        "        cls_id = torch.LongTensor([self.tokenizer.convert_tokens_to_ids(\"[CLS]\")]).cuda()\n",
        "        cls_id = cls_id.unsqueeze(0).expand(bsz, 1)\n",
        "        cls_token_embeds = self.word_embeddings(cls_id)\n",
        "\n",
        "        sep_id = torch.LongTensor([self.tokenizer.convert_tokens_to_ids(\"[SEP]\")]).cuda()\n",
        "        sep_id = sep_id.unsqueeze(0).expand(bsz, 1)\n",
        "        sep_token_embeds = self.word_embeddings(sep_id)\n",
        "\n",
        "        imgs_embeddings = self.img_embeddings(input_imgs)\n",
        "        token_embeddings = torch.cat(\n",
        "            [cls_token_embeds, imgs_embeddings, sep_token_embeds], dim=1\n",
        "        )\n",
        "\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long).cuda()\n",
        "        position_ids = position_ids.unsqueeze(0).expand(bsz, seq_length)\n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "        embeddings = token_embeddings + position_embeddings + token_type_embeddings\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class MultimodalRobertaEncoder(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super(MultimodalRobertaEncoder, self).__init__()\n",
        "        bert = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "        self.txt_embeddings = bert.embeddings\n",
        "\n",
        "        ternary_embeds = nn.Embedding(3, hidden_sz)\n",
        "        ternary_embeds.weight.data[:2].copy_(\n",
        "        bert.embeddings.token_type_embeddings.weight\n",
        "            )\n",
        "        ternary_embeds.weight.data[2].copy_(\n",
        "                bert.embeddings.token_type_embeddings.weight.data.mean(dim=0)\n",
        "            )\n",
        "        self.txt_embeddings.token_type_embeddings = ternary_embeds\n",
        "\n",
        "        self.img_embeddings = ImageBertEmbeddings(self.txt_embeddings)\n",
        "        self.img_encoder = ImageEncoder()\n",
        "        self.encoder = bert.encoder\n",
        "        self.pooler = bert.pooler\n",
        "        self.num_image_embeds = num_image_embeds\n",
        "\n",
        "    def forward(self, input_txt, attention_mask, segment, input_img):\n",
        "        bsz = input_txt.size(0)\n",
        "        attention_mask = torch.cat(\n",
        "            [\n",
        "                torch.ones(bsz, self.num_image_embeds + 2).long().cuda(),\n",
        "                attention_mask,\n",
        "            ],\n",
        "            dim=1,\n",
        "        )\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "        extended_attention_mask = extended_attention_mask.to(\n",
        "            dtype=next(self.parameters()).dtype\n",
        "        )\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "\n",
        "        img_tok = (\n",
        "            torch.LongTensor(input_txt.size(0), self.num_image_embeds + 2)\n",
        "            .fill_(0)\n",
        "            .cuda()\n",
        "        )\n",
        "        img = self.img_encoder(input_img)  # BxNx3x224x224 -> BxNx2048\n",
        "        img_embed_out = self.img_embeddings(img, img_tok)\n",
        "        txt_embed_out = self.txt_embeddings(input_txt, segment)\n",
        "        encoder_input = torch.cat([img_embed_out, txt_embed_out], 1)  # Bx(TEXT+IMG)xHID\n",
        "\n",
        "        encoded_layers = self.encoder(\n",
        "            encoder_input, extended_attention_mask)#, output_all_encoded_layers=False)\n",
        "\n",
        "        return self.pooler(encoded_layers[-1])\n",
        "\n",
        "\n",
        "class MultimodalBertClf(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super(MultimodalBertClf, self).__init__()\n",
        "\n",
        "        self.enc = MultimodalRobertaEncoder()\n",
        "        self.clf1 = nn.Linear(hidden_sz, n_classes)\n",
        "\n",
        "    def forward(self, txt, mask, segment, img):\n",
        "        x = self.enc(txt, mask, segment, img)\n",
        "        out_head1 = self.clf1(x)\n",
        "        return (out_head1)"
      ],
      "metadata": {
        "id": "Zqg-O5jpOwzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Forward method"
      ],
      "metadata": {
        "id": "PmK5VUxOGXCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_forward(i_epoch, model, criterion, batch):\n",
        "    txt, segment, mask, img, tgt1 = batch\n",
        "\n",
        "    for param in model.enc.img_encoder.parameters():\n",
        "        param.requires_grad = not freeze_img\n",
        "    for param in model.enc.encoder.parameters():\n",
        "        param.requires_grad = not freeze_txt\n",
        "\n",
        "    txt, img = txt.cuda(), img.cuda()\n",
        "    mask, segment = mask.cuda(), segment.cuda()\n",
        "\n",
        "    out1 = model(txt, mask, segment, img)\n",
        "\n",
        "    tgt1 = tgt1.cuda()\n",
        "    loss1 = criterion(out1, tgt1)\n",
        "\n",
        "    return loss1, out1, tgt1"
      ],
      "metadata": {
        "id": "iJyj2J3744Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate and predict"
      ],
      "metadata": {
        "id": "9UfGLQoKGdKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_eval(i_epoch, data, model, criterion, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds1, tgts1 = [], [], []\n",
        "        for batch in data:\n",
        "            loss, out1, tgt1 = model_forward(i_epoch, model, criterion, batch)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            pred1 = torch.sigmoid(out1).cpu().detach().numpy() > 0.5\n",
        "\n",
        "            preds1.append(pred1)\n",
        "\n",
        "            tgt1 = tgt1.cpu().detach().numpy()\n",
        "            tgts1.append(tgt1)\n",
        "\n",
        "    metrics = {\"loss_mean_overall\": np.mean(losses)}\n",
        "    tgts1 = np.vstack(tgts1)\n",
        "    preds1 = np.vstack(preds1)\n",
        "    metrics[\"macro_f1\"] = f1_score(tgts1, preds1, average=\"macro\")\n",
        "    metrics[\"micro_f1\"] = f1_score(tgts1, preds1, average=\"micro\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def model_pred(i_epoch, data, model, criterion, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds1, tgts1 = [], [], []\n",
        "        for batch in data:\n",
        "            loss, out1, tgt1 = model_forward(i_epoch, model, criterion, batch)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            pred1 = torch.sigmoid(out1).cpu().detach().numpy() > 0.5\n",
        "            preds1.append(pred1)\n",
        "\n",
        "            tgt1 = tgt1.cpu().detach().numpy()\n",
        "            tgts1.append(tgt1)\n",
        "\n",
        "        return (tgts1, preds1)"
      ],
      "metadata": {
        "id": "CRfzFUnT49gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initiating model"
      ],
      "metadata": {
        "id": "pRPa4jl9Hk13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "set_seed(seed)\n",
        "savedir = os.path.join(savedir, name)\n",
        "os.makedirs(savedir, exist_ok=True)\n",
        "\n",
        "train_loader, val_loader, test_loaders = get_data_loaders()\n",
        "\n",
        "model = MultimodalBertClf()\n",
        "criterion = get_criterion()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = get_scheduler(optimizer)\n",
        "\n",
        "logger = create_logger(\"%s/logfile.log\" % savedir)\n",
        "logger.info(model)\n",
        "model.cuda()\n",
        "\n",
        "start_epoch, global_step, n_no_improve, best_metric = 0, 0, 0, -np.inf\n",
        "\n",
        "if os.path.exists(os.path.join(savedir, \"checkpoint.pt\")):\n",
        "        checkpoint = torch.load(os.path.join(savedir, \"checkpoint.pt\"))\n",
        "        start_epoch = checkpoint[\"epoch\"]\n",
        "        n_no_improve = checkpoint[\"n_no_improve\"]\n",
        "        best_metric = checkpoint[\"best_metric\"]\n",
        "        model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "        scheduler.load_state_dict(checkpoint[\"scheduler\"])"
      ],
      "metadata": {
        "id": "Xq4X_GGu4usY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "VoU-cgLL1TiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "logger.info(\"Training..\")\n",
        "for i_epoch in range(start_epoch, max_epochs):\n",
        "        train_losses = []\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch in tqdm(train_loader, total=len(train_loader)):\n",
        "            loss, _, _ = model_forward(i_epoch, model,criterion, batch)\n",
        "            if gradient_accumulation_steps > 1:\n",
        "                loss = loss / gradient_accumulation_steps\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            global_step += 1\n",
        "            if global_step % gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        metrics = model_eval(i_epoch, val_loader, model, criterion)\n",
        "        logger.info(\"Train Loss: {:.4f}\".format(np.mean(train_losses)))\n",
        "        log_metrics(\"Val\", metrics,logger)\n",
        "\n",
        "        tuning_metric = metrics[\"micro_f1\"]\n",
        "\n",
        "        scheduler.step(tuning_metric)\n",
        "        is_improvement = tuning_metric > best_metric\n",
        "        if is_improvement:\n",
        "            best_metric = tuning_metric\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            n_no_improve += 1\n",
        "\n",
        "        save_checkpoint(\n",
        "            {\n",
        "                \"epoch\": i_epoch + 1,\n",
        "                \"state_dict\": model.state_dict(),\n",
        "                \"optimizer\": optimizer.state_dict(),\n",
        "                \"scheduler\": scheduler.state_dict(),\n",
        "                \"n_no_improve\": n_no_improve,\n",
        "                \"best_metric\": best_metric,\n",
        "            },\n",
        "            is_improvement,\n",
        "            savedir,\n",
        "        )\n",
        "\n",
        "        if n_no_improve >= patience:\n",
        "            logger.info(\"No improvement. Breaking out of loop.\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-zG51bLax3o",
        "outputId": "c42d0953-1476-4461-ff92-d09454f15877"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO - 01/09/23 09:01:24 - 0:00:04 - Training..\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.94it/s]\n",
            "INFO - 01/09/23 09:02:20 - 0:01:00 - Train Loss: 0.0411\n",
            "INFO - 01/09/23 09:02:20 - 0:01:00 - Val: Loss_mean_overall: 0.94827 | Macro F1 0.27295 | Micro F1: 0.52525\n",
            "100%|██████████| 99/99 [00:52<00:00,  1.89it/s]\n",
            "INFO - 01/09/23 09:03:37 - 0:02:17 - Train Loss: 0.0399\n",
            "INFO - 01/09/23 09:03:37 - 0:02:17 - Val: Loss_mean_overall: 0.93341 | Macro F1 0.36093 | Micro F1: 0.55517\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.93it/s]\n",
            "INFO - 01/09/23 09:04:50 - 0:03:30 - Train Loss: 0.0382\n",
            "INFO - 01/09/23 09:04:50 - 0:03:30 - Val: Loss_mean_overall: 0.83606 | Macro F1 0.50697 | Micro F1: 0.57072\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.94it/s]\n",
            "INFO - 01/09/23 09:06:03 - 0:04:43 - Train Loss: 0.0350\n",
            "INFO - 01/09/23 09:06:03 - 0:04:43 - Val: Loss_mean_overall: 0.78855 | Macro F1 0.53420 | Micro F1: 0.60556\n",
            "100%|██████████| 99/99 [00:52<00:00,  1.89it/s]\n",
            "INFO - 01/09/23 09:07:18 - 0:05:58 - Train Loss: 0.0308\n",
            "INFO - 01/09/23 09:07:18 - 0:05:58 - Val: Loss_mean_overall: 0.68457 | Macro F1 0.64433 | Micro F1: 0.65957\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.93it/s]\n",
            "INFO - 01/09/23 09:08:32 - 0:07:12 - Train Loss: 0.0255\n",
            "INFO - 01/09/23 09:08:32 - 0:07:12 - Val: Loss_mean_overall: 0.61851 | Macro F1 0.66876 | Micro F1: 0.72429\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.94it/s]\n",
            "INFO - 01/09/23 09:09:45 - 0:08:25 - Train Loss: 0.0229\n",
            "INFO - 01/09/23 09:09:45 - 0:08:25 - Val: Loss_mean_overall: 0.56665 | Macro F1 0.69853 | Micro F1: 0.74169\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.92it/s]\n",
            "INFO - 01/09/23 09:10:59 - 0:09:39 - Train Loss: 0.0201\n",
            "INFO - 01/09/23 09:10:59 - 0:09:39 - Val: Loss_mean_overall: 0.53534 | Macro F1 0.73340 | Micro F1: 0.78022\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.94it/s]\n",
            "INFO - 01/09/23 09:12:12 - 0:10:52 - Train Loss: 0.0179\n",
            "INFO - 01/09/23 09:12:12 - 0:10:52 - Val: Loss_mean_overall: 0.50017 | Macro F1 0.76803 | Micro F1: 0.80973\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.90it/s]\n",
            "INFO - 01/09/23 09:13:26 - 0:12:06 - Train Loss: 0.0152\n",
            "INFO - 01/09/23 09:13:26 - 0:12:06 - Val: Loss_mean_overall: 0.46405 | Macro F1 0.76399 | Micro F1: 0.81243\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.94it/s]\n",
            "INFO - 01/09/23 09:14:39 - 0:13:19 - Train Loss: 0.0133\n",
            "INFO - 01/09/23 09:14:39 - 0:13:19 - Val: Loss_mean_overall: 0.45884 | Macro F1 0.76618 | Micro F1: 0.82103\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.93it/s]\n",
            "INFO - 01/09/23 09:15:53 - 0:14:33 - Train Loss: 0.0115\n",
            "INFO - 01/09/23 09:15:53 - 0:14:33 - Val: Loss_mean_overall: 0.44884 | Macro F1 0.78519 | Micro F1: 0.83705\n",
            "100%|██████████| 99/99 [00:52<00:00,  1.89it/s]\n",
            "INFO - 01/09/23 09:17:07 - 0:15:47 - Train Loss: 0.0098\n",
            "INFO - 01/09/23 09:17:07 - 0:15:47 - Val: Loss_mean_overall: 0.45522 | Macro F1 0.77473 | Micro F1: 0.81093\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.93it/s]\n",
            "INFO - 01/09/23 09:18:12 - 0:16:52 - Train Loss: 0.0092\n",
            "INFO - 01/09/23 09:18:12 - 0:16:52 - Val: Loss_mean_overall: 0.43435 | Macro F1 0.80921 | Micro F1: 0.84527\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.92it/s]\n",
            "INFO - 01/09/23 09:19:26 - 0:18:06 - Train Loss: 0.0078\n",
            "INFO - 01/09/23 09:19:26 - 0:18:06 - Val: Loss_mean_overall: 0.44109 | Macro F1 0.81139 | Micro F1: 0.83922\n",
            "100%|██████████| 99/99 [00:52<00:00,  1.89it/s]\n",
            "INFO - 01/09/23 09:20:32 - 0:19:12 - Train Loss: 0.0069\n",
            "INFO - 01/09/23 09:20:32 - 0:19:12 - Val: Loss_mean_overall: 0.46983 | Macro F1 0.80073 | Micro F1: 0.84272\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.93it/s]\n",
            "INFO - 01/09/23 09:21:37 - 0:20:17 - Train Loss: 0.0055\n",
            "INFO - 01/09/23 09:21:37 - 0:20:17 - Val: Loss_mean_overall: 0.44217 | Macro F1 0.80313 | Micro F1: 0.83959\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00017: reducing learning rate of group 0 to 5.0000e-05.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 99/99 [00:51<00:00,  1.93it/s]\n",
            "INFO - 01/09/23 09:22:41 - 0:21:21 - Train Loss: 0.0048\n",
            "INFO - 01/09/23 09:22:41 - 0:21:21 - Val: Loss_mean_overall: 0.42673 | Macro F1 0.80813 | Micro F1: 0.85052\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.91it/s]\n",
            "INFO - 01/09/23 09:23:56 - 0:22:36 - Train Loss: 0.0042\n",
            "INFO - 01/09/23 09:23:56 - 0:22:36 - Val: Loss_mean_overall: 0.43363 | Macro F1 0.80786 | Micro F1: 0.84571\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.93it/s]\n",
            "INFO - 01/09/23 09:25:01 - 0:23:41 - Train Loss: 0.0039\n",
            "INFO - 01/09/23 09:25:01 - 0:23:41 - Val: Loss_mean_overall: 0.42378 | Macro F1 0.81236 | Micro F1: 0.85287\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.92it/s]\n",
            "INFO - 01/09/23 09:26:15 - 0:24:55 - Train Loss: 0.0035\n",
            "INFO - 01/09/23 09:26:15 - 0:24:55 - Val: Loss_mean_overall: 0.43979 | Macro F1 0.81081 | Micro F1: 0.85219\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.93it/s]\n",
            "INFO - 01/09/23 09:27:19 - 0:25:59 - Train Loss: 0.0034\n",
            "INFO - 01/09/23 09:27:19 - 0:25:59 - Val: Loss_mean_overall: 0.44624 | Macro F1 0.81590 | Micro F1: 0.85349\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.93it/s]\n",
            "INFO - 01/09/23 09:28:33 - 0:27:13 - Train Loss: 0.0029\n",
            "INFO - 01/09/23 09:28:33 - 0:27:13 - Val: Loss_mean_overall: 0.44596 | Macro F1 0.81241 | Micro F1: 0.84925\n",
            "100%|██████████| 99/99 [00:52<00:00,  1.90it/s]\n",
            "INFO - 01/09/23 09:29:38 - 0:28:18 - Train Loss: 0.0028\n",
            "INFO - 01/09/23 09:29:38 - 0:28:18 - Val: Loss_mean_overall: 0.44823 | Macro F1 0.80992 | Micro F1: 0.85057\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.93it/s]\n",
            "INFO - 01/09/23 09:30:43 - 0:29:23 - Train Loss: 0.0027\n",
            "INFO - 01/09/23 09:30:43 - 0:29:23 - Val: Loss_mean_overall: 0.45865 | Macro F1 0.81188 | Micro F1: 0.85219\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00025: reducing learning rate of group 0 to 2.5000e-05.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 99/99 [00:50<00:00,  1.95it/s]\n",
            "INFO - 01/09/23 09:31:48 - 0:30:28 - Train Loss: 0.0025\n",
            "INFO - 01/09/23 09:31:48 - 0:30:28 - Val: Loss_mean_overall: 0.45596 | Macro F1 0.81481 | Micro F1: 0.85450\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.92it/s]\n",
            "INFO - 01/09/23 09:33:02 - 0:31:42 - Train Loss: 0.0023\n",
            "INFO - 01/09/23 09:33:02 - 0:31:42 - Val: Loss_mean_overall: 0.45388 | Macro F1 0.81353 | Micro F1: 0.85287\n",
            "100%|██████████| 99/99 [00:50<00:00,  1.94it/s]\n",
            "INFO - 01/09/23 09:34:06 - 0:32:46 - Train Loss: 0.0023\n",
            "INFO - 01/09/23 09:34:06 - 0:32:46 - Val: Loss_mean_overall: 0.45890 | Macro F1 0.81263 | Micro F1: 0.84890\n",
            "100%|██████████| 99/99 [00:50<00:00,  1.94it/s]\n",
            "INFO - 01/09/23 09:35:10 - 0:33:50 - Train Loss: 0.0022\n",
            "INFO - 01/09/23 09:35:10 - 0:33:50 - Val: Loss_mean_overall: 0.47046 | Macro F1 0.78372 | Micro F1: 0.84758\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00029: reducing learning rate of group 0 to 1.2500e-05.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 99/99 [00:51<00:00,  1.92it/s]\n",
            "INFO - 01/09/23 09:36:15 - 0:34:55 - Train Loss: 0.0021\n",
            "INFO - 01/09/23 09:36:15 - 0:34:55 - Val: Loss_mean_overall: 0.47016 | Macro F1 0.78616 | Micro F1: 0.84988\n",
            "100%|██████████| 99/99 [00:50<00:00,  1.95it/s]\n",
            "INFO - 01/09/23 09:37:20 - 0:36:00 - Train Loss: 0.0021\n",
            "INFO - 01/09/23 09:37:20 - 0:36:00 - Val: Loss_mean_overall: 0.46619 | Macro F1 0.78382 | Micro F1: 0.84624\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.93it/s]\n",
            "INFO - 01/09/23 09:38:24 - 0:37:04 - Train Loss: 0.0021\n",
            "INFO - 01/09/23 09:38:24 - 0:37:04 - Val: Loss_mean_overall: 0.46887 | Macro F1 0.78755 | Micro F1: 0.85052\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00032: reducing learning rate of group 0 to 6.2500e-06.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:51<00:00,  1.92it/s]\n",
            "INFO - 01/09/23 09:39:29 - 0:38:09 - Train Loss: 0.0021\n",
            "INFO - 01/09/23 09:39:29 - 0:38:09 - Val: Loss_mean_overall: 0.47201 | Macro F1 0.78710 | Micro F1: 0.84954\n",
            "100%|██████████| 99/99 [00:51<00:00,  1.94it/s]\n",
            "INFO - 01/09/23 09:40:33 - 0:39:13 - Train Loss: 0.0021\n",
            "INFO - 01/09/23 09:40:33 - 0:39:13 - Val: Loss_mean_overall: 0.47514 | Macro F1 0.78608 | Micro F1: 0.84855\n",
            "100%|██████████| 99/99 [00:50<00:00,  1.95it/s]\n",
            "INFO - 01/09/23 09:41:38 - 0:40:18 - Train Loss: 0.0020\n",
            "INFO - 01/09/23 09:41:38 - 0:40:18 - Val: Loss_mean_overall: 0.47650 | Macro F1 0.78801 | Micro F1: 0.84988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 00035: reducing learning rate of group 0 to 3.1250e-06.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:51<00:00,  1.92it/s]\n",
            "INFO - 01/09/23 09:42:43 - 0:41:23 - Train Loss: 0.0021\n",
            "INFO - 01/09/23 09:42:43 - 0:41:23 - Val: Loss_mean_overall: 0.47634 | Macro F1 0.79159 | Micro F1: 0.84988\n",
            "INFO - 01/09/23 09:42:51 - 0:41:31 - No improvement. Breaking out of loop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "kqPsBP7ZIDmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_checkpoint(model, \"/content/save_dir/nameless/model_best.pt\")\n",
        "model.eval()\n",
        "test_metrics = model_eval(\n",
        "            np.inf, test_loaders, model, criterion, store_preds=False\n",
        "        )\n",
        "\n",
        "print('test_metrics')\n",
        "print()\n",
        "test_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLWeD2mByCM1",
        "outputId": "bb0f9814-74e7-4b63-a6e0-0936fa98752b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_metrics\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss_mean_overall': 0.5442859019551959,\n",
              " 'macro_f1': 0.8334651599239125,\n",
              " 'micro_f1': 0.8565400843881857}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}